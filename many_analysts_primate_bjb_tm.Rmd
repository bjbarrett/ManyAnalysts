---
title: "ManyAnalysts"
author: "Brendan Barrett and Tracy Montgomery"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
library(rethinking)
library(janitor)
library(aniDom)
library(gtools)
set_ulam_cmdstan(TRUE)
```

# Open or Read the four files
```{r load}
## Load data
library(janitor)
d_demo <- clean_names(read.csv("Data/demographics.csv"))
d_disp <- clean_names(read.csv("Data/displacements.csv"))
d_groom <- clean_names(read.csv("Data/grooming.csv"))
d_ot <- clean_names(read.csv("Data/observation_times.csv"))
str(d_demo)
str(d_disp)
str(d_groom)
str(d_ot)
```

# Calculate dominance ranks for all individuals

First, I will do some basic checks that will allow me to fix typos in names and other common data entry errors.

```{r}
# check that all ids in demography are unique
anyDuplicated(d_demo$id)  #none duplicated

# check that all the individuals in the displacements file are in the demography file
unique(d_disp$sender %in% d_demo$id)   #all senders in demography
unique(d_disp$receiver %in% d_demo$id)   #all receivers in demography

# check that displacements recorded correctly (one of the individuals was the subject of the focal follow)
unique(d_disp$focal == d_disp$sender | d_disp$focal == d_disp$receiver)   #all displacements involve a focal animal
```

Because I don't know exactly how the data were collected, I won't check for overlapping cases or other common errors in behavioral data.

Next, I will check the displacements data set for the criteria required to accurately calculate a dominance hierarchy.

```{r}
# do all the individuals interact at least once? 
sort(unique(c(d_disp$sender, d_disp$receiver))) == sort(unique(d_demo$id))  #all demography individuals in displacements

# is anyone interacting with themselves?
unique(d_disp$sender == d_disp$receiver) #all senders different from receivers

# estimate sampling effort (ratio of interactions to individuals)
round(nrow(d_disp)/length(unique(c(d_disp$sender, d_disp$receiver))))  #36 (should be at least 10-20)

# estimate sparseness of dataset - not done b/c no reason to expect that simulated data would be too sparse
```

For a longitudinal primate study, I would calculate dominance ranks that are sensitive to time and sequences of events. However, since this study is only 1 year long with no prior information on this species (and thus no reason to expect that dominance ranks would be changing within a single year), I will generate a static dominance hierarchy using all of the data collected.

I will use the randomized Elo-rating to calculate hierarchies for this species following Sánchez-Tójar et al. 2017 (doi: 10.1111/1365-2656.12776). This method is valid across a variety of levels of hierarchy steepness, and as a bonus it allows us to estimate hierarchy uncertainty. 

```{r}
# rank based on randomized Elo-rating
rand_scores <- elo_scores(winners = d_disp$sender,
                          losers = d_disp$receiver,
                          identities = d_demo$id,
                          K = 100, #following Neumann et al. 2011
                          randomise = TRUE,
                          n.rands = 1000)
rand_scores <- rand_scores[order(rowMeans(rand_scores), decreasing = T),] #order based on final score

# plot ranks (not scores)
plot_ranks(ranks = rand_scores, plot.CIs = T)

# calculate means and sds of scores
scores_summ <- data.frame(id = row.names(rand_scores), mean_score = rowMeans(rand_scores),
                    sd_score = matrixStats::rowSds(rand_scores))
```

I have provided raw scores, rather than ranks, as it is more conveniently distributed for modeling than ordinal ranks. I made `rand_scores`, a matrix (raw scores x 1000 randomizations) and `scores_summ`, a data frame (mean and SD of the randomizations).

Next I will estimate the uncertainty of the hierarchy.

```{r}
# uncertainty/steepness based on Elo-rating repeatability
rept <- estimate_uncertainty_by_repeatability(winners = d_disp$sender,
                                              losers = d_disp$receiver,
                                              identities = d_demo$id,
                                              init.score = 0,
                                              n.rands = 1000)
#squanch <- round(rept,3)    #0.971
```

This measure of steepness/uncertainty is independent of both group size and the ratio of interactions to individuals. The value obtained is `r round(rept,3)`, which indicates that the hierarchy of this group of primates is very steep, and therefore, the estimate of ranks is highly certain.

# Prepare grooming interactions

For the social relations model I will build, all individuals will need the same indexing variable to fit in `stan`. I will now see that all individuals in the `demography.csv` are represented in all of the grooming columns
```{r}
#rm(rept)   #clean environment
# Lets check that all the individuals in the demography files are represented in the sender and reciever component of the grooming data
sort(unique(d_demo$id)) == sort(unique(d_groom$sender)) # true all represented
sort(unique(d_groom$sender)) == sort(unique(d_groom$receiver)) # true all represented
sort(unique(d_groom$receiver)) ==  sort(unique(d_demo$id)) # true all represented
sort(unique(d_demo$id)) == sort(unique(d_groom$focal)) # true all represented

```
This looks good so we can assign indexing variables to these datasets at least.
```{r}
d_demo$id_index <- as.integer(as.factor(d_demo$id))
d_groom$r_index <- as.integer(as.factor(d_groom$receiver))
d_groom$s_index <- as.integer(as.factor(d_groom$sender))
d_groom$f_index <- as.integer(as.factor(d_groom$focal))
```

Now lets inspect the duration seconds column to see what we be working with.

```{r, echo=TRUE}
hist(d_groom$duration_seconds) # dass even
is.integer(d_groom$duration_second) # all integers
# for(i in 1:max(d_groom$f_index)){
#   dens( d_groom$duration_seconds[d_groom$s_index==i] , col="salmon", xlim=range(d_groom$duration_seconds) )
#   dens( d_groom$duration_seconds[d_groom$r_index==i] , col="mediumpurple3" , add=TRUE)
# }
```
The data looks to be all integers and all greater that zero. 
However, this data only shows instances where grooming occurred.
There is the possibility that in some dyads grooming did not occure (i.e. we recorded a 0).
We can get this by counting how much grooming did not occur based off of the observation time of the dyad.
Since we are estimating rates, a log-link function that accounts for different exposures seems good.
A gamma distribution would be a good choice, as it is the natural distribution for times.
But we *could* use a a Poisson which would likely give the same answer, but time is continuous, so we will go with that even though the data is collected in integers (it is technically measurement error, but we shall ignore that).
Depending on frequency of zeros, a zero-augmented gamma or zero-inflated poisson might be a good model to fit.

Another thing I want to inspect is if there are duplicate rows.
Sometimes people will duplicate an observation row to account for two individuals belonging to the dyad in grooming data (As grooming is a dyadic behavior). 
This is wrong as it leads to overconfident or misleading estimates, and folks often eff up the varying effects structure.

```{r}
table(d_groom$duration_seconds) # this has odd numbers so observations not duplicated
```
Above has some odd numbers of durations observed so observations not duplicated.

### Exposure and observation effort
The `grooming.csv` file is data from focal follows where one individual is in a follow.
I do not know how long each focal follow was from this dataset.
But I will make the assumption that they are all the same length, so the exposure is the same.
Since I do not know is a follow is 10 minutes or 10 seconds, I cannot make predictions on a real scale.
And `d_do$observation_time` does noy have units, but I will see if it is number of follows?

```{r}
str(d_ot)
sort(unique(d_ot$focal))==sort(unique(d_demo$id)) # all true so represented
d_ot2 <- as.data.frame(table(d_groom$focal ) )
#sort(d_ot2$Freq)==sort(d_ot$observation_time)
sum(d_ot$observation_time) # this is close, but not equal to the 2800 hours, so i will assume observation time is number of hours
#sum(d_ot2$Freq)
```
The summed about of focal observation time is `r sum(d_ot$observation_time)`, which is close to the 2800 hours in the prompt so I will assume this contains focal hours.

A choice we have to make is what exposure we will choose. 
If I were to collect this data, I would have the exposure estimated per focal follow, and analyze data on that scale.
I would have formatted the data as grooming observations within a focal follow, and also noted if no grooming occurred during a follow.
From this finest grained approach one can look at the dynamics or rank and grooming rates over time.

Back to exposure--- we know the cumulative time that an individual was observed in hours.
We have a record of the duration bout of each grooming bout, but we cannot link that to a focal follow.
So, what we can say is given a known sampling rate of individuals in focal follows, we can estimate an exposure *per individual* or *per dyad*.
The individual exposure will have us estimate directional grooming rates of a given dyad within the cumulative time that one of the dyad members was followed.
The dyadic approach implies that given how long a dyad was sampled (i.e. summed observation time of individial $i$ and individual $j$), what are the estimated directional grooming rates of a given dyad.
Both will give us the same answer, just the individual approach has double the rows.
Since grooming rates is a dyadic property, we will take that approach. 

### Assigning dyad ID
I am going to make a unique dyad variable now.
```{r}
d_groom$dyad <- apply(d_groom[,2:3], 1, function(s) paste0(sort(s), collapse='_'))
sort(unique(d_groom$dyad))
d_groom$dyad_index <- as.integer(as.factor(d_groom$dyad))
table(d_groom$dyad)
```
From the table, we can see that there are multiple observations of some dyads engaging in grooming.
Lets look at a particularly groomy dyad.
```{r}
d_groom[d_groom$dyad=="Andrew_Kristen",]
```
I am somewhat concerned that at `x=1328` and `x=2003`, we see at the same timestamp two grooming events for the same sender that exceed a minute. 
I think this is a simulation or data management error, but this would give me concern if I saw this in a dataset about the quality.

Can add 0 per observation, to account for no simultaneous grooming..
However prompt posits no simultaneous grooming, so we can compress this.
Outcome is also in seconds, whereas exposure is in hours (i think, so we will have to do some math to get our prediction scales good with the exposure, which will also affect our distributional choice).

### Aggregating the data frame into analyzable form
```{r}

#set up blanck vectors
d_groom$groomAB <- d_groom$groomBA <- d_groom$A_id <- d_groom$B_id <- d_groom$A <- d_groom$B <- d_groom$exposure_dyad_hours <-   NA 

for(i in 1:nrow(d_groom)){
  d_groom$A_id[i] <- min( c(d_groom$s_index[i] , d_groom$r_index[i] ) ) #index of individual A in dyad (alphabetical first)
  d_groom$B_id[i] <- max( c(d_groom$s_index[i] , d_groom$r_index[i] ) ) #index of individual B in dyad (alphabetical first)
  d_groom$A[i] <- min( c(d_groom$sender[i] , d_groom$receiver[i] ) ) #individual A in dyad (alphabetical first)
  d_groom$B[i] <- max( c(d_groom$sender[i] , d_groom$receiver[i] ) ) #individual B in dyad (alphabetical first)
  d_groom$groomAB[i] <-  sum(d_groom$duration_seconds[d_groom$dyad_index==d_groom$dyad_index[i] & d_groom$s_index==d_groom$A_id[i]]) #how much A grooms B, in a particular dyad across all observations
  d_groom$groomBA[i] <-  sum(d_groom$duration_seconds[d_groom$dyad_index==d_groom$dyad_index[i] & d_groom$r_index==d_groom$A_id[i]]) #how much B grooms A, in a particular dyad across all observations
}


                                                 
# for( i in 1:max(d_groom$dyad_index))){
#   d_groom$aid <- sort(unique(d_groom$f_index[d_groom$dyad_index==1]))[1]
#   bid <- sort(unique(d_groom$f_index[d_groom$dyad_index==1]))[1]
#   d_groom$groomAB[i] <- sum(d_groom$duration_seconds[d_groom$dyad_index==i d_groom$s_index==d_groom$f_index[i] 
#                                       & d_groom$s_index==d_groom$s_index[i] & d_groom$dyad_index==d_groom$dyad_index[i]]) 
#   d_groom$focal_receive_groom[i] <- sum(d_groom$duration_seconds[d_groom$r_index==d_groom$f_index[i] 
#                                       & d_groom$r_index==d_groom$r_index[i] & d_groom$dyad_index==d_groom$dyad_index[i]])
# }

d_groom2 <- d_groom[,c("dyad" , "dyad_index" , "A_id" , "B_id" , "A" , "B" , "groomAB" , "groomBA")] #subset the columns i will use

d_groom3 <-d_groom2[!duplicated(d_groom2), ] # drop da dupes, individual dataframe
## now lets add exposure
d_groom3$exposure_dyad_hour <- NA
# add up the observation time for each dyad in hours (sum of focal follows for each dyad member)
for (i in 1:nrow(d_groom3)){
  d_groom3$exposure_dyad_hour[i] <- sum(d_ot$observation_time[which(d_ot$focal==d_groom3$A[i])] , d_ot$observation_time[which(d_ot$focal==d_groom3$B[i])])
}
str(d_groom3)

#lots of zeros, so i'll likely have to do a ZIP

#lets add sex, age, and rank of dyad mambers
d_groom3$sex_A <- d_groom3$sex_B <- d_groom3$age_A <- d_groom3$age_B <- NA
d_demo$age_std <- standardize(d_demo$age)
for (i in 1:nrow(d_groom3)){
  d_groom3$sex_A[i] <- d_demo$sex[which(d_demo$id==d_groom3$A[i])]
  d_groom3$sex_B[i] <- d_demo$sex[which(d_demo$id==d_groom3$B[i])]
  d_groom3$age_std_A[i] <- d_demo$age_std[which(d_demo$id==d_groom3$A[i])]
  d_groom3$age_std_B[i] <- d_demo$age_std[which(d_demo$id==d_groom3$B[i])]
}
  d_groom3$sex_A_index <- as.integer(as.factor(d_groom3$sex_A))
  d_groom3$sex_B_index <- as.integer(as.factor(d_groom3$sex_B))
```
# Prepare outcome and predictor variables
I put all this stuff in a list
```{r list}
datalist <- list(
  N_dyads = length(unique(d_groom3$dyad_index)) ,
  N_i = length(unique(d_demo$id)) ,
  groomAB = d_groom3$groomAB,
  groomBA = d_groom3$groomBA,
  A_id = d_groom3$A_id,
  B_id = d_groom3$B_id,
  dyad_id = d_groom3$dyad_index,
  exposure_dyad_hour = d_groom3$exposure_dyad_hour ,
  exposure_dyad_day = d_groom3$exposure_dyad_hour/24,
  sex_A_index = d_groom3$sex_A_index,
  sex_B_index = d_groom3$sex_B_index,
  age_std_A = d_groom3$age_std_A,
  age_std_B = d_groom3$age_std_B,
  groomAB_minperday=d_groom3$groomAB/(d_groom3$exposure_dyad_hour/24) ,
  groomBA_minperday=d_groom3$groomBA/(d_groom3$exposure_dyad_hour/24)
)
#sort(unique(datalist$groomAB))
hist(c(d_groom3$groomAB,d_groom3$groomBA) , breaks=100)
table(c(d_groom3$groomAB,d_groom3$groomBA))
nrow(d_groom3)
```
# Analysis - please perform all model checks you feel are appropriate
## Poisson Intercepts only social relations model.

Barreling forward, I will first do an intercepts only version of the social relations model to see how much heterogeneity is explained by dyadic or individual level variation, using the `ulam` function in the `rethinking` package in `R`
```{r , eval=FALSE}
m0 <- ulam(
    alist(
        groomAB ~ poisson( lambda_AB ),
        groomBA ~ poisson( lambda_BA ),
        log(lambda_AB) <- a + gr[A_id,1] + gr[B_id,2] + d[dyad_id,1] ,
        log(lambda_BA) <- a + gr[B_id,1] + gr[A_id,2] + d[dyad_id,2] ,
        a ~ normal(1,2),
        ## gr matrix of varying effects
        vector[2]:gr[N_i] ~ multi_normal(0,Rho_gr,sigma_gr),
        Rho_gr ~ lkj_corr(4),
        sigma_gr ~ exponential(1),
       ## dyad effects choleskyfied
        transpars> matrix[N_dyads,2]:d <-
                compose_noncentered( rep_vector(sigma_d,2) , L_Rho_d , zd ),
        matrix[2,N_dyads]:zd ~ normal( 0 , 1 ),
        cholesky_factor_corr[2]:L_Rho_d ~ lkj_corr_cholesky( 8 ),
        sigma_d ~ exponential(1),
       ## compute correlation matrix for dyads
        gq> matrix[2,2]:Rho_d <<- Chol_to_Corr( L_Rho_d )

    ), data=datalist , chains=4 , cores=4 , iter=2000 , control=list(adapt_delta=0.99 , max_treedepth=14))

```
Below is code for a Poisson version of the model which has treedepth issues
```{r intercepts only}
#lets add exposure
dens(exp(rnorm(n=30000 ,3,1.1)))

m0exp <- ulam(
    alist(
        groomAB ~ poisson( lambda_AB ),
        groomBA ~ poisson( lambda_BA ),
        log(lambda_AB) <- a + gr[A_id,1] + gr[B_id,2] + d[dyad_id,1] + log(exposure_dyad_day),
        log(lambda_BA) <- a + gr[B_id,1] + gr[A_id,2] + d[dyad_id,2] + log(exposure_dyad_day),
        a ~ normal(3,1.1),
        vector[2]:gr[N_i] ~ multi_normal(0,Rho_gr,sigma_gr),
        Rho_gr ~ lkj_corr(4),
        sigma_gr ~ exponential(1),
       ## dyad effects choleskyfied
        transpars> matrix[N_dyads,2]:d <-
                compose_noncentered( rep_vector(sigma_d,2) , L_Rho_d , zd ),
        matrix[2,N_dyads]:zd ~ normal( 0 , 1 ),
        cholesky_factor_corr[2]:L_Rho_d ~ lkj_corr_cholesky( 4 ),
        sigma_d ~ exponential(1),
       ## compute correlation matrix for dyads
        gq> matrix[2,2]:Rho_d <<- Chol_to_Corr( L_Rho_d )

    ), data=datalist , chains=8 , cores=8 , iter=2000 , cmdstan=TRUE  )

```
Lets look at model ouput of individuals:

```{r precis int only}
precis(m0exp , depth=3 , pars=c( "a" ,"sigma_gr" , "Rho_gr","sigma_d" ,"Rho_d"))
post <- extract.samples( m0exp)
dens(exp(post$a) , xlab="posterior of seconds groomed/day")
abline( v=median(exp(post$a)) )
```
So $\alpha$ implies a median grooming rate of `r median(exp(post$a)` minutes/hour. We also see more variation in dyads then we do in individuals, and more variation in receiving grooming(`sigma_gr[2]`) thatn giving grooming (`sigma_gr[1]`).

```{r int only grafs link}
g <- sapply( 1:60 , function(i) post$a + post$gr[,i,1] )
r <- sapply( 1:60 , function(i) post$a + post$gr[,i,2] )
Eg_mu <- apply( exp(g) , 2 , median )
Er_mu <- apply( exp(r) , 2 , median )
#g_mu <- apply( g , 2 , median )
#Er_mu <- apply( r , 2 , median )
plot( NULL , xlim=c(0,16) , ylim=c(0,16) , xlab="generalized giving grooming" ,
    ylab="generalized receiving grooming" , lwd=1.5 )
abline(a=0,b=1,lty=2)

# ellipses
library(ellipse)
for ( i in 1:60 ) {
    Sigma <- cov( cbind( g[,i] , r[,i] ) )
    Mu <- c( mean(g[,i]) , mean(r[,i]) )
    for ( l in c(0.5) ) {
        el <- ellipse( Sigma , centre=Mu , level=l )
        lines( exp(el) , col=col.alpha("black",0.5) )
    }
}
# household means
points( Eg_mu , Er_mu , pch=21 , bg="white" , lwd=1.5 )
```
```{r int only grafs}
g <- sapply( 1:60 , function(i) post$a + post$gr[,i,1] )
r <- sapply( 1:60 , function(i) post$a + post$gr[,i,2] )
g_mu <- apply( g , 2 , median )
r_mu <- apply( r , 2 , median )
plot( NULL , xlim=c(-15,15) , ylim=c(-15,15) , xlab="generalized giving grooming (log-link scale)" ,
    ylab="generalized receiving grooming (log-link scale)" , lwd=1.5 )
abline(a=0,b=1,lty=2)

# ellipses
library(ellipse)
for ( i in 1:60 ) {
    Sigma <- cov( cbind( g[,i] , r[,i] ) )
    Mu <- c( mean(g[,i]) , mean(r[,i]) )
    for ( l in c(0.5) ) {
        el <- ellipse( Sigma , centre=Mu , level=l )
        lines( el , col=col.alpha("black",0.5) )
    }
}
# household means
points( g_mu , r_mu , pch=21 , bg="white" , lwd=1.5 )
```
The above graphs visualize the strong negative correlations between giving grooming and receiving grooming, ignoring dyad specific effects..
Individuals that receive alot of grooming, give less on average. This is reflected by the high values of $\rho$ in the varaicne covariance matrix.

Now we can look ay dyad specific effects, ignoring generalized tendency of individuals to give and receive.
Within dyads
```{r}
dy1 <- apply( post$d[,,1] , 2 , median )
dy2 <- apply( post$d[,,2] , 2 , median )
plot( dy1 , dy2 , xlim=c(-9,9) , ylim=c(-9,9) , xlab="primate B in dyad" , ylab="primate B in dyad")
```
There is a reliable negative correlation within dyads, after accounting for generalzed tendecies of individual to give and recieve grooming. If one individual in a dyad grooms a lot, the other likely grooms a little. Dyads are unbalanced. Their is strong separation in varying effects which likely means something is unmodeled (or fitting issues) that structures the data.
```{r intercepts only}
## Zero-inflated Poisson Intercepts only social relations model.

#lets add exposure and make it a ZiPoisson
m0expZI <- ulam(
    alist(
      groomAB ~ dzipois( pAB, lambda_AB ),
      groomBA ~ dzipois( pBA , lambda_BA ),
      logit(pAB) <- a_z + gr[A_id,1] + gr[B_id,2] + log(exposure_dyad_day),
      logit(pBA) <- a_z + gr[B_id,1] + gr[A_id,2] + log(exposure_dyad_day),
      log(lambda_AB) <- a + gr[A_id,3] + gr[B_id,4] + d[dyad_id,1]  + log(exposure_dyad_day),
      log(lambda_BA) <- a + gr[B_id,3] + gr[A_id,4] + d[dyad_id,2]  + log(exposure_dyad_day),
      a ~ normal(3,1.1),
      a_z ~ normal(0,1),
      vector[4]:gr[N_i] ~ multi_normal(0,Rho_gr,sigma_gr),
      Rho_gr ~ lkj_corr(4),
      sigma_gr ~ exponential(1),
       ## dyad effects choleskyfied
       transpars> matrix[N_dyads,2]:d <-
             compose_noncentered( rep_vector(sigma_d,2) , L_Rho_d , zd ),
       matrix[2,N_dyads]:zd ~ normal( 0 , 1 ),
       cholesky_factor_corr[2]:L_Rho_d ~ lkj_corr_cholesky( 4 ),
       sigma_d ~ exponential(1),
       ## compute correlation matrix for dyads
      gq> matrix[2,2]:Rho_d <<- Chol_to_Corr( L_Rho_d )

    ), data=datalist , chains=8 , cores=8 , iter=2000 , cmdstan = TRUE  )

precis(m0expZI , pars=c("a", "a_z"))
precis(m0expZI , depth=2 , pars=c( "sigma_d" ))
precis(m0expZI , pars=c( "sigma_d" , "sigma_gr" ) , depth=3)
precis(m0expZI , pars=c("Rho_gr" , "Rho_d") , depth=3)

```

```{r , eval=FALSE}
m0expZI1 <- ulam(
    alist(
      groomAB ~ dzipois( pAB, lambda_AB ),
      groomBA ~ dzipois( pBA , lambda_BA ),
      logit(pAB) <- a_z + gr[A_id,1] + gr[B_id,2] + d[dyad_id,1] +  log(exposure_dyad_hour),
      logit(pBA) <- a_z + gr[B_id,1] + gr[A_id,2] + d[dyad_id,2]  + log(exposure_dyad_hour),
      log(lambda_AB) <- a + gr[A_id,3] + gr[B_id,4]  + d[dyad_id,3] + log(exposure_dyad_hour),
      log(lambda_BA) <- a + gr[B_id,3] + gr[A_id,4]  + d[dyad_id,4] + log(exposure_dyad_hour),
      
      a ~ normal(3,1.1),
      a_z ~ normal(0,1),
      vector[4]:gr[N_i] ~ multi_normal(0,Rho_gr,sigma_gr),
      Rho_gr ~ lkj_corr(4),
      sigma_gr ~ exponential(1),
      
      # dyad effects choleskyfied
      transpars> matrix[N_dyads,4]:d <-
        compose_noncentered( rep_vector(sigma_d,4) , L_Rho_d , zd ),
      matrix[4,N_dyads]:zd ~ normal( 0 , 1 ),
      cholesky_factor_corr[4]:L_Rho_d ~ lkj_corr_cholesky( 4 ),
      sigma_d ~ exponential(1),
      # compute correlation matrix for dyads
      gq> matrix[4,4]:Rho_d <<- Chol_to_Corr( L_Rho_d )

    ), data=datalist , chains=8 , cores=8 , iter=2000 , cmdstan = TRUE  )
```
This is the one we will use
```{r}
m0expZI2 <- ulam(
    alist(
        groomAB ~ dzipois( pAB, lambda_AB ),
        groomBA ~ dzipois( pBA , lambda_BA ),
        logit(pAB) <- a_z + gr_z[A_id,1] + gr_z[B_id,2] + d_z[dyad_id,1]  + log(exposure_dyad_day),
        logit(pBA) <- a_z + gr_z[B_id,1] + gr_z[A_id,2] + d_z[dyad_id,2]  + log(exposure_dyad_day),
        log(lambda_AB) <- a + gr[A_id,1] + gr[B_id,2] + d[dyad_id,1]  + log(exposure_dyad_day),
        log(lambda_BA) <- a + gr[B_id,1] + gr[A_id,2] + d[dyad_id,2]  + log(exposure_dyad_day),
        a_z ~ normal(0,1),
        a ~ normal(3,1.1),
        vector[2]:gr_z[N_i] ~ multi_normal(0,Rho_gr_z,sigma_gr_z),
        Rho_gr_z ~ lkj_corr(4),
        sigma_gr_z ~ exponential(1),
        vector[2]:gr[N_i] ~ multi_normal(0,Rho_gr,sigma_gr),
        Rho_gr ~ lkj_corr(4),
        sigma_gr ~ exponential(1),
## dyad effects choleskyfied
      transpars> matrix[N_dyads,2]:d_z <-
            compose_noncentered( rep_vector(sigma_d_z,2) , L_Rho_d_z , zd_z ),
      matrix[2,N_dyads]:zd_z ~ normal( 0 , 1 ),
      cholesky_factor_corr[2]:L_Rho_d_z ~ lkj_corr_cholesky( 4 ),
      sigma_d_z ~ exponential(1),
      transpars> matrix[N_dyads,2]:d <-
             compose_noncentered( rep_vector(sigma_d,2) , L_Rho_d , zd ),
       matrix[2,N_dyads]:zd ~ normal( 0 , 1 ),
       cholesky_factor_corr[2]:L_Rho_d ~ lkj_corr_cholesky( 4 ),
       sigma_d ~ exponential(1),
## compute correlation matrix for dyads
      gq> matrix[2,2]:Rho_d_z <<- Chol_to_Corr( L_Rho_d_z ),
      gq> matrix[2,2]:Rho_d <<- Chol_to_Corr( L_Rho_d )
    ), data=datalist , chains=8 , cores=8 , iter=3000 , cmdstan = TRUE  )

precis(m0expZI2 , pars=c("Rho_d_z","Rho_d") , depth=3)
precis(m0expZI2 , pars=c("a","a_z") , depth=3 )
precis(m0expZI2 , pars=c("Rho_gr_z","Rho_gr") , depth=3)
```

# append_row(sigma_d, sigma_g)
```{r}
m0expZI4 <- ulam(
    alist(
        groomAB ~ dzipois( pAB, lambda_AB ),
        groomBA ~ dzipois( pBA , lambda_BA ),
        logit(pAB) <- a_z + gr[A_id,1] + gr[B_id,2] + d_z[dyad_id] + log(exposure_dyad_hour),
        logit(pBA) <- a_z + gr[B_id,1] + gr[A_id,2] + d_z[dyad_id] + log(exposure_dyad_hour),
        log(lambda_AB) <- a + gr[A_id,3] + gr[B_id,4] + d[dyad_id,1]  + log(exposure_dyad_hour),
        log(lambda_BA) <- a + gr[B_id,3] + gr[A_id,4] + d[dyad_id,2]  + log(exposure_dyad_hour),
        a ~ normal(3,1.1),
        a_z ~ normal(0,1),
      d_z[N_dyads] ~ normal(0,sigma_dz),
      vector[4]:gr[N_i] ~ multi_normal(0,Rho_gr,sigma_gr),
      Rho_gr ~ lkj_corr(4),
      sigma_gr ~ exponential(1),
      sigma_dz ~ exponential(1),
       ## dyad effects choleskyfied
      #combo_sigma <- append_row( rep_vector(sigma_d[1],2) , rep_vector(sigma_d[2],2)) ,
       transpars> matrix[N_dyads,2]:d <-
             compose_noncentered( sigma_gr , L_Rho_d , zd ),
       matrix[2,N_dyads]:zd ~ normal( 0 , 1 ),
       cholesky_factor_corr[2]:L_Rho_d ~ lkj_corr_cholesky( 4 ),
       sigma_d ~ exponential(1),
       ## compute correlation matrix for dyads
      gq> matrix[2,2]:Rho_d <<- Chol_to_Corr( L_Rho_d )

    ), data=datalist , chains=8 , cores=8 , iter=2000 , cmdstan = TRUE  ) 
```
# Visualise or describe impact of Sex
We will start with Poisson.
I am adding a parameter `bx_gr` for sex.
First colum is sex effects of grooming, second is sex effects of receiving grooming. First row is effects for females, second is for males.
```{r}
m0exp_sex <- ulam(
    alist(
        groomAB ~ poisson( lambda_AB ),
        groomBA ~ poisson( lambda_BA ),
        log(lambda_AB) <- a + gr[A_id,1] + gr[B_id,2] + d[dyad_id,1] 
        + bx_gr[sex_A_index,1] + bx_gr[sex_B_index,2] + log(exposure_dyad_day),
        log(lambda_BA) <- a + gr[B_id,1] + gr[A_id,2] + d[dyad_id,2]
         + bx_gr[sex_B_index,1] + bx_gr[sex_A_index,2] + log(exposure_dyad_day),
        a ~ normal(1,1.2),
        matrix[2,2]:bx_gr ~ dnorm( 0 , 1 ), #first column is grooming effects, second is receiving effects, #row 1 is females, row 2 males
        vector[2]:gr[N_i] ~ multi_normal(0,Rho_gr,sigma_gr),
        Rho_gr ~ lkj_corr(4),
        sigma_gr ~ exponential(1),
       ## dyad effects choleskyfied
        transpars> matrix[N_dyads,2]:d <-
                compose_noncentered( rep_vector(sigma_d,2) , L_Rho_d , zd ),
        matrix[2,N_dyads]:zd ~ normal( 0 , 1 ),
        cholesky_factor_corr[2]:L_Rho_d ~ lkj_corr_cholesky( 4 ),
        sigma_d ~ exponential(1),
       ## compute correlation matrix for dyads
        gq> matrix[2,2]:Rho_d <<- Chol_to_Corr( L_Rho_d )

    ), data=datalist , chains=8 , cores=8 , iter=8000)
```


Lets look at the ouput.
```{r}
precis(m0exp_sex , depth=3 , pars=c("a" , "bx_gr" , "sigma_gr" , "sigma_d" ))
```
And now lets graph predictions. Unsuprisingly Poisson is poorly specified, given the high amount of zeros.
```{r}
#post <- extract.samples(m0exp_sex)
dens(exp(post$a + post$bx_gr[,1,1]) , col="darkred" , ylim=c(-.12,0.9) , xlim=c(0,500) , main="Within-Dyad Grooming Rates Per Hour") #females send grooming
dens(exp(post$a + post$bx_gr[,1,2]) , col="red" , add=TRUE) #females receive grooming
dens(exp(post$a + post$bx_gr[,2,1]) , col="darkblue" , add=TRUE) #males send grooming
dens(exp(post$a + post$bx_gr[,2,2]) , col="cornflowerblue" , add=TRUE) #males receive grooming
dens( exp(rnorm( n=nrow(post$a) , mean=2 ,sd=1.5 ) ) , lty=3 , add=TRUE , adj=0.9)
#females grooming
frog <- which(datalist$sex_A_index==1)
points(datalist$groomAB_minperday[frog] , rep(-.02, length(datalist$groomAB_minperday[frog]) ) , pch=1 ,col=col.alpha("darkred"))
frog <- which(datalist$sex_B_index==1)
points(datalist$groomBA_minperday[frog] , rep(-.02, length(datalist$groomAB_minperday[frog]) ) , pch=1 ,col=col.alpha("darkred"))
#males grooming
frog <- which(datalist$sex_A_index==2)
points(datalist$groomAB_minperday[frog] , rep(-.05, length(datalist$groomAB_minperday[frog]) ) , pch=1 ,col=col.alpha("darkblue"))
frog <- which(datalist$sex_B_index==2)
points(datalist$groomBA_minperday[frog] , rep(-.05, length(datalist$groomAB_minperday[frog]) ) , pch=1 ,col=col.alpha("darkblue"))
#females receiving
frog <- which(datalist$sex_B_index==1)
points(datalist$groomAB_minperday[frog] , rep(-.08, length(datalist$groomAB_minperday[frog]) ) , pch="x" ,col=col.alpha("red"))
frog <- which(datalist$sex_A_index==1)
points(datalist$groomBA_minperday[frog] , rep(-.08, length(datalist$groomAB_minperday[frog]) ) , pch="x" ,col=col.alpha("red"))
#males receiving
frog <- which(datalist$sex_B_index==2)
points(datalist$groomAB_minperday[frog] , rep(-.11, length(datalist$groomAB_minperday[frog]) ) , pch="x" ,col=col.alpha("cornflowerblue"))
frog <- which(datalist$sex_A_index==2)
points(datalist$groomBA_minperday[frog] , rep(-.11, length(datalist$groomAB_minperday[frog]) ) , pch="x" ,col=col.alpha("cornflowerblue"))
```
```{r}

m0ZIexp_sex <- ulam(
    alist(
        groomAB ~ dzipois( pAB, lambda_AB ),
        groomBA ~ dzipois( pBA , lambda_BA ),
        ## bernouli sanders likelihood
        logit(pAB) <- a_z + gr_z[A_id,1] + gr_z[B_id,2] + d_z[dyad_id,1]
        + bx_gr_z[sex_A_index,1] + bx_gr_z[sex_B_index,2] + log(exposure_dyad_day),
        logit(pBA) <- a_z + gr_z[B_id,1] + gr_z[A_id,2] + d_z[dyad_id,2]
        + bx_gr_z[sex_B_index,1] + bx_gr_z[sex_A_index,2] + log(exposure_dyad_day),
        ## Poisson likelhood
        log(lambda_AB) <- a + gr[A_id,1] + gr[B_id,2] + d[dyad_id,1]  
        + bx_gr[sex_A_index,1] + bx_gr[sex_B_index,2] + log(exposure_dyad_day),
        log(lambda_BA) <- a + gr[B_id,1] + gr[A_id,2] + d[dyad_id,2]
        + bx_gr[sex_B_index,1] + bx_gr[sex_A_index,2] + log(exposure_dyad_day),
        #fixed effects priors
        a_z ~ normal(0,1),
        a ~ normal(3,1.1),
        matrix[2,2]:bx_gr_z ~ dnorm( 0 , 1 ),
        matrix[2,2]:bx_gr ~ dnorm( 0 , 1 ),
        #bernouli give/receive priors
        vector[2]:gr_z[N_i] ~ multi_normal(0,Rho_gr_z,sigma_gr_z),
        Rho_gr_z ~ lkj_corr(4),
        sigma_gr_z ~ exponential(1),
        #Poisson give/receive priors
        vector[2]:gr[N_i] ~ multi_normal(0,Rho_gr,sigma_gr),
        Rho_gr ~ lkj_corr(4),
        sigma_gr ~ exponential(1),
## dyad effects choleskyfied
     #bernouli dyad priors
      transpars> matrix[N_dyads,2]:d_z <-
            compose_noncentered( rep_vector(sigma_d_z,2) , L_Rho_d_z , zd_z ),
      matrix[2,N_dyads]:zd_z ~ normal( 0 , 1 ),
      cholesky_factor_corr[2]:L_Rho_d_z ~ lkj_corr_cholesky( 4 ),
      sigma_d_z ~ exponential(1),
     #Poisson dyad priors
      transpars> matrix[N_dyads,2]:d <-
             compose_noncentered( rep_vector(sigma_d,2) , L_Rho_d , zd ),
       matrix[2,N_dyads]:zd ~ normal( 0 , 1 ),
       cholesky_factor_corr[2]:L_Rho_d ~ lkj_corr_cholesky( 4 ),
       sigma_d ~ exponential(1),
## compute correlation matrix for dyads in generated quantities
      gq> matrix[2,2]:Rho_d_z <<- Chol_to_Corr( L_Rho_d_z ),
      gq> matrix[2,2]:Rho_d <<- Chol_to_Corr( L_Rho_d )
    ), data=datalist , chains=8 , cores=8 , iter=3000 , cmdstan = TRUE  )

```
```{r}
precis(m0ZIexp_sex , pars=c("a" , "a_z" , "bx_gr_z" , "bx_gr" , "sigma_d_z" , "sigma_gr_z" ,"sigma_d" , "sigma_gr"  ) , depth=3)
```

```{r}

m1ZIexp_sex <- ulam(
    alist(
        groomAB ~ dzipois( pAB, lambda_AB ),
        groomBA ~ dzipois( pBA , lambda_BA ),
        ## bernouli sanders likelihood
        logit(pAB) <- a_z + gr_z[A_id,1] + gr_z[B_id,2] + d_z[dyad_id,1]
        + bx_gr_z[sex_A_index,1] + bx_gr_z[sex_B_index,2] + log(exposure_dyad_day),
        logit(pBA) <- a_z + gr_z[B_id,1] + gr_z[A_id,2] + d_z[dyad_id,2]
        + bx_gr_z[sex_B_index,1] + bx_gr_z[sex_A_index,2] + log(exposure_dyad_day),
        ## Poisson likelhood
        log(lambda_AB) <- a + gr[A_id,1] + gr[B_id,2] + d[dyad_id,1]  
        + bx_gr[sex_A_index,1] + bx_gr[sex_B_index,2] + log(exposure_dyad_day),
        log(lambda_BA) <- a + gr[B_id,1] + gr[A_id,2] + d[dyad_id,2]
        + bx_gr[sex_B_index,1] + bx_gr[sex_A_index,2] + log(exposure_dyad_day),
        #fixed effects priors
        a_z ~ normal(0,1),
        a ~ normal(3,1.1),
        matrix[2,2]:bx_gr_z ~ dnorm( 0 , 1 ),
        matrix[2,2]:bx_gr ~ dnorm( 0 , 1 ),
        
## dyad effects choleskyfied
     #bernouli dyad priors
      transpars> matrix[N_dyads,2]:d_z <-
            compose_noncentered( rep_vector(sigma_d_z,2) , L_Rho_d_z , zd_z ),
      matrix[2,N_dyads]:zd_z ~ normal( 0 , 1 ),
      cholesky_factor_corr[2]:L_Rho_d_z ~ lkj_corr_cholesky( 4 ),
      sigma_d_z ~ exponential(1),

      transpars> matrix[N_i,2]:gr_z <-
            compose_noncentered( rep_vector(sigma_gr_z,2) , L_Rho_gr_z , zgr_z ),
      matrix[2,N_i]:zgr_z ~ normal( 0 , 1 ),
      cholesky_factor_corr[2]:L_Rho_gr_z ~ lkj_corr_cholesky( 4 ),
      sigma_gr_z ~ exponential(1),

     #Poisson dyad priors
      transpars> matrix[N_dyads,2]:d <-
             compose_noncentered( rep_vector(sigma_d,2) , L_Rho_d , zd ),
       matrix[2,N_dyads]:zd ~ normal( 0 , 1 ),
       cholesky_factor_corr[2]:L_Rho_d ~ lkj_corr_cholesky( 6 ),
       sigma_d ~ exponential(1),

      transpars> matrix[N_i,2]:gr <-
            compose_noncentered( rep_vector(sigma_gr,2) , L_Rho_gr , zgr ),
      matrix[2,N_i]:zgr ~ normal( 0 , 1 ),
      cholesky_factor_corr[2]:L_Rho_gr ~ lkj_corr_cholesky( 6 ),
      sigma_gr ~ exponential(1),

## compute correlation matrix for dyads in generated quantities
      gq> matrix[2,2]:Rho_d_z <<- Chol_to_Corr( L_Rho_d_z ),
      gq> matrix[2,2]:Rho_d <<- Chol_to_Corr( L_Rho_d ),
      gq> matrix[2,2]:Rho_gr_z <<- Chol_to_Corr( L_Rho_gr_z ),
      gq> matrix[2,2]:Rho_gr <<- Chol_to_Corr( L_Rho_gr )
    ), data=datalist , chains=8 , cores=8 , iter=3000 , cmdstan = TRUE  )

```

```{r}
precis(m1ZIexp_sex , pars=c("a" , "a_z" , "bx_gr_z" , "bx_gr" ) , depth=3)
precis(m1ZIexp_sex , pars=c( "sigma_d_z" , "sigma_gr_z" ,"sigma_d" , "sigma_gr"   ) , depth=3)
precis(m0ZIexp_sex , pars=c("Rho_d_z", "Rho_d" , "Rho_gr_z"  ,"Rho_gr" ) , depth=3)

```
Now we shall draw samples from the posterior. to generate predictions for mean effects.
```{r}
post <- extract.samples(m1ZIexp_sex)
bern_pred_sex <- cbind(1-logistic(post$a_z + post$bx_gr_z[,1,1]),
                1-logistic(post$a_z + post$bx_gr_z[,1,2]),
                1-logistic(post$a_z + post$bx_gr_z[,2,1]), 
                1-logistic(post$a_z + post$bx_gr_z[,2,2])
                )

pois_pred_sex <- cbind(exp(post$a + post$bx_gr[,1,1]),
                exp(post$a + post$bx_gr[,1,2]),
                exp(post$a + post$bx_gr[,2,1]), 
                exp(post$a + post$bx_gr[,2,2])
                )
joint_pred_sex <- bern_pred_sex*pois_pred_sex
```

We can generate predictions for mean effects from the Bernouli component of the model. The probability of observing a 1, or the probability of grooming in a day
```{r}
dens(bern_pred_sex[,1] , col="darkred" , ylim=c(-.12,25) , xlim=c(0,1) , xlab="probability of grooming in a day") #females send grooming
dens(bern_pred_sex[,2], col="red" , add=TRUE , lty=2) #females receive grooming
dens(bern_pred_sex[,3] , col="darkblue" , add=TRUE) #males send grooming
dens(bern_pred_sex[,4] , col="cornflowerblue" , add=TRUE , lty=2) #males receive grooming
dens( logistic(rnorm( n=nrow(post$a) , mean=0 ,sd=1 ) ) , lty=3 , add=TRUE , adj=0.9)
```
It looks like females and males are equally likely to receive grooming in a day ($PME_{females_r}$= {`r median(bern_pred_sex[,2])` }, 89 \% HPDI= {`r HPDI(bern_pred_sex[,2])`}; $PME_{males_r}$= {`r median(bern_pred_sex[,4]) ` }, 89 \% HPDI= {`r HPDI(bern_pred_sex[,4])` }.
Females are more likely to groom than males ($PME_{females_g}$= {`r median(bern_pred_sex[,2])` }, 89 \% HPDI= {`r HPDI(bern_pred_sex[,2]) `}; $PME_{males_g}$= {` r median(bern_pred_sex[,3]) `}, 89 \% HPDI= {`r HPDI(bern_pred_sex[,3])` }.

Now we can look at the Poisson component of the model.
```{r}
dens(pois_pred_sex[,1] , col="darkred" , ylim=c(0,.03) , xlim=c(0,300) , xlab="within-dyad grooming rate (mins/day), conditional on grooming occuring") #females send grooming
dens(pois_pred_sex[,2], col="red" , add=TRUE , lty=2) #females receive grooming
dens(pois_pred_sex[,3] , col="darkblue" , add=TRUE) #males send grooming
dens(pois_pred_sex[,4] , col="cornflowerblue" , add=TRUE , lty=2) #males receive grooming
dens( exp(rnorm( n=nrow(post$a) , mean=3 ,sd=1.1 ) ) , lty=3 , add=TRUE , adj=0.9) #prior
```
Now lets look at the joint posterior
```{r}
dens(joint_pred_sex[,1] , col="darkred" , ylim=c(-.007,.03) , xlim=c(0,450) , xlab="within-dyad grooming rate (mins/day)") #females send grooming
dens(joint_pred_sex[,2], col="red" , add=TRUE , lty=2) #females receive grooming
dens(joint_pred_sex[,3]*pois_pred_sex[,3] , col="darkblue" , add=TRUE) #males send grooming
dens(joint_pred_sex[,4] , col="cornflowerblue" , add=TRUE , lty=2) #males receive grooming
#females grooming
frog <- which(datalist$sex_A_index==1)
points(datalist$groomAB_minperday[frog] , rep(-.001, length(datalist$groomAB_minperday[frog]) ) , pch=1 ,col=col.alpha(alpha=0.1,"darkred"))
frog <- which(datalist$sex_B_index==1)
points(datalist$groomBA_minperday[frog] , rep(-.001, length(datalist$groomAB_minperday[frog]) ) , pch=1 ,col=col.alpha(alpha=0.1,"darkred"))
#males grooming
frog <- which(datalist$sex_A_index==2)
points(datalist$groomAB_minperday[frog] , rep(-.003, length(datalist$groomAB_minperday[frog]) ) , pch=1 ,col=col.alpha(alpha=0.1,"darkblue"))
frog <- which(datalist$sex_B_index==2)
points(datalist$groomBA_minperday[frog] , rep(-.003, length(datalist$groomAB_minperday[frog]) ) , pch=1 ,col=col.alpha(alpha=0.1,"darkblue"))
#females receiving
frog <- which(datalist$sex_B_index==1)
points(datalist$groomAB_minperday[frog] , rep(-.005, length(datalist$groomAB_minperday[frog]) ) , pch="x" ,col=col.alpha(alpha=0.1,"red"))
frog <- which(datalist$sex_A_index==1)
points(datalist$groomBA_minperday[frog] , rep(-.005, length(datalist$groomAB_minperday[frog]) ) , pch="x" ,col=col.alpha(alpha=0.1,"red"))
#males receiving
frog <- which(datalist$sex_B_index==2)
points(datalist$groomAB_minperday[frog] , rep(-.007, length(datalist$groomAB_minperday[frog]) ) , pch="x" ,col=col.alpha(alpha=0.1,"cornflowerblue"))
frog <- which(datalist$sex_A_index==2)
points(datalist$groomBA_minperday[frog] , rep(-.007, length(datalist$groomAB_minperday[frog]) ) , pch="x" ,col=col.alpha(alpha=0.1,"cornflowerblue"))
```

#plot prob of not grooming
dens(exp(post$a + post$bx_gr[,1,1]))

dens(exp(post$a + post$bx_gr[,1,1]) , col="darkred" , ylim=c(-.12,0.9) , xlim=c(0,500) , main="Within-Dyad Grooming Rates Per Hour") #females send grooming
dens(exp(post$a + post$bx_gr[,1,2]) , col="red" , add=TRUE) #females receive grooming
dens(exp(post$a + post$bx_gr[,2,1]) , col="darkblue" , add=TRUE) #males send grooming
dens(exp(post$a + post$bx_gr[,2,2]) , col="cornflowerblue" , add=TRUE) #males receive grooming
dens( exp(rnorm( n=nrow(post$a) , mean=2 ,sd=1.5 ) ) , lty=3 , add=TRUE , adj=0.9)
#females grooming
frog <- which(datalist$sex_A_index==1)
points(datalist$groomAB_minperday[frog] , rep(-.02, length(datalist$groomAB_minperday[frog]) ) , pch=1 ,col=col.alpha("darkred"))
frog <- which(datalist$sex_B_index==1)
points(datalist$groomBA_minperday[frog] , rep(-.02, length(datalist$groomAB_minperday[frog]) ) , pch=1 ,col=col.alpha("darkred"))
#males grooming
frog <- which(datalist$sex_A_index==2)
points(datalist$groomAB_minperday[frog] , rep(-.05, length(datalist$groomAB_minperday[frog]) ) , pch=1 ,col=col.alpha("darkblue"))
frog <- which(datalist$sex_B_index==2)
points(datalist$groomBA_minperday[frog] , rep(-.05, length(datalist$groomAB_minperday[frog]) ) , pch=1 ,col=col.alpha("darkblue"))
#females receiving
frog <- which(datalist$sex_B_index==1)
points(datalist$groomAB_minperday[frog] , rep(-.08, length(datalist$groomAB_minperday[frog]) ) , pch="x" ,col=col.alpha("red"))
frog <- which(datalist$sex_A_index==1)
points(datalist$groomBA_minperday[frog] , rep(-.08, length(datalist$groomAB_minperday[frog]) ) , pch="x" ,col=col.alpha("red"))
#males receiving
frog <- which(datalist$sex_B_index==2)
points(datalist$groomAB_minperday[frog] , rep(-.11, length(datalist$groomAB_minperday[frog]) ) , pch="x" ,col=col.alpha("cornflowerblue"))
frog <- which(datalist$sex_A_index==2)
points(datalist$groomBA_minperday[frog] , rep(-.11, length(datalist$groomAB_minperday[frog]) ) , pch="x" ,col=col.alpha("cornflowerblue"))
```

#1 Visualise or describe impact of Age
Individuals do not age, so we will do age as a fixed effect. 
I will consider this independent of sex, as the prompt did not ask to interact the two.

```{r}
m0exp_age <- ulam(
    alist(
        groomAB ~ poisson( lambda_AB ),
        groomBA ~ poisson( lambda_BA ),
        log(lambda_AB) <- a + gr[A_id,1] + gr[B_id,2] + d[dyad_id,1] 
        + ba_gr[1]*age_std_A + ba_gr[2]*age_std_B + log(exposure_dyad_day),
        log(lambda_BA) <- a + gr[B_id,1] + gr[A_id,2] + d[dyad_id,2]
         + ba_gr[1]*age_std_B + ba_gr[2]*age_std_A + log(exposure_dyad_day),
        a ~ normal(0.1,2),
        vector[2]:ba_gr ~ dnorm( 0 , 1 ), #first column is grooming effects, second is receiving effects,
        vector[2]:gr[N_i] ~ multi_normal(0,Rho_gr,sigma_gr),
        Rho_gr ~ lkj_corr(4),
        sigma_gr ~ exponential(1),
       ## dyad effects choleskyfied
        transpars> matrix[N_dyads,2]:d <-
                compose_noncentered( rep_vector(sigma_d,2) , L_Rho_d , zd ),
        matrix[2,N_dyads]:zd ~ normal( 0 , 1 ),
        cholesky_factor_corr[2]:L_Rho_d ~ lkj_corr_cholesky( 4 ),
        sigma_d ~ exponential(1),
       ## compute correlation matrix for dyads
        gq> matrix[2,2]:Rho_d <<- Chol_to_Corr( L_Rho_d )

    ), data=datalist ,   control = list(adapt_delta = 0.99,
                 max_treedepth = 15), chains=6 , cores=20 , iter=8000)
precis(m0ZIexp_age , pars=c("a" , "sigma_d" ,"sigma_gr" , "ba_gr" ), depth=2)
```
```{r}
plot(datalist$groomAB~datalist$age_std_A , pch=19 , col=col.alpha("slateblue") )
points(datalist$groomBA~datalist$age_std_B, pch=19 , col=col.alpha("slateblue"))
```
# Visualise or describe impact of Rank
```{r}
plot(datalist$groomAB~datalist$age_std_A , pch=19 , col=col.alpha("slateblue") )
points(datalist$groomBA~datalist$age_std_B, pch=19 , col=col.alpha("slateblue"))
```
